{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: bigdl-llm[all] in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (2.4.0b20231003)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from bigdl-llm[all]) (9.0.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from bigdl-llm[all]) (4.24.4)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from bigdl-llm[all]) (1.25.1)\n",
      "Requirement already satisfied: torch in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from bigdl-llm[all]) (2.0.1)\n",
      "Requirement already satisfied: transformers==4.31.0 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from bigdl-llm[all]) (4.31.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from bigdl-llm[all]) (0.1.99)\n",
      "Requirement already satisfied: tokenizers==0.13.3 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from bigdl-llm[all]) (0.13.3)\n",
      "Requirement already satisfied: accelerate==0.21.0 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from bigdl-llm[all]) (0.21.0)\n",
      "Requirement already satisfied: tabulate in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from bigdl-llm[all]) (0.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from accelerate==0.21.0->bigdl-llm[all]) (23.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from accelerate==0.21.0->bigdl-llm[all]) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from accelerate==0.21.0->bigdl-llm[all]) (6.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (0.16.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (2023.6.3)\n",
      "Requirement already satisfied: requests in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from torch->bigdl-llm[all]) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from torch->bigdl-llm[all]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from torch->bigdl-llm[all]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from torch->bigdl-llm[all]) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0->bigdl-llm[all]) (2023.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from tqdm>=4.27->transformers==4.31.0->bigdl-llm[all]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from jinja2->torch->bigdl-llm[all]) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from requests->transformers==4.31.0->bigdl-llm[all]) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from requests->transformers==4.31.0->bigdl-llm[all]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from requests->transformers==4.31.0->bigdl-llm[all]) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from requests->transformers==4.31.0->bigdl-llm[all]) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from sympy->torch->bigdl-llm[all]) (1.3.0)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: transformers_stream_generator in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (0.0.4)\n",
      "Requirement already satisfied: transformers>=4.26.1 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers_stream_generator) (4.31.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (1.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (2023.6.3)\n",
      "Requirement already satisfied: requests in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (4.65.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.26.1->transformers_stream_generator) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.26.1->transformers_stream_generator) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from tqdm>=4.27->transformers>=4.26.1->transformers_stream_generator) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install bigdl-llm[all]\n",
    "\n",
    "# Additional package required for Baichuan-13B-Chat to conduct generation\n",
    "!pip install -U transformers_stream_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\86177\\anaconda3\\envs\\vllm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bigdl.llm.transformers import AutoModelForCausalLM\n",
    "\n",
    "model_path = \"C:\\LLM\\llm-model\\saved-int4-models\\Baichuan-13B-Chat\"\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_path,\n",
    "#                                             load_in_4bit=True,\n",
    "#                                             trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.load_low_bit(model_path,trust_remote_code=True)\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path,\n",
    "                                          trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.generation.utils import GenerationConfig\n",
    "model.generation_config = GenerationConfig.from_pretrained(\"C:\\LLM\\llm-model\\saved-int4-models\\Baichuan-13B-Chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multistep_prompt_zjh_1(user_input):\n",
    "    return f\"\"\"您是一个大型语言模型提示词撰写专家。\n",
    "        用户的输入可能涉及一个复杂的问题，如果直接让语言模型回答这个问题效果并不好。你的目的是将用户的问题拆分为几个小问题，让语言模型一步步思考，逐渐靠近答案。优化过的问题将以“请逐个回答上述问题，一步步思考。”结尾。\n",
    "\n",
    "        例子：\n",
    "        输入：\n",
    "        我希望按欧式风格装修房子，要花费多少钱？\n",
    "\n",
    "        修改后的输入：\n",
    "        1.AI助手你好，请你告诉我，欧式风格的房子主要有哪些家具？\\n2.AI助手你好，请你告诉我，欧式风格的家具一般需要多少钱？\\n3.AI助手你好，请你告诉我，完成欧式风格的装修总共需要多少钱？\\n请逐个回答上述问题，一步步思考。\n",
    "\n",
    "        原来的输入如下：\n",
    "        {user_input}\n",
    "\n",
    "        修改的输入如下：\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def multistep_prompt_prompter(question):\n",
    "    messages = []\n",
    "    messages.append({\"role\":\"user\",\"content\":multistep_prompt_zjh_1(question)})\n",
    "    response = model.chat(tokenizer, messages)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_prompt_zjh_1(user_history):\n",
    "    return f\"\"\"您是独属于该用户的提示词管家。\n",
    "        您会定期看到用户向大型语言模型提问的历史记录，你需要根据这些历史提问，提取出几个用户的特征，包括但不限于使用语言、倾向于提出的问题类型、提问的立场、用户可能的身份、经常犯的逻辑谬误等等。\n",
    "        我们会将这些特征加入到大型语言模型的prompt中，以便于模型更好地理解用户的提问。\n",
    "        你需要在每个特征前面加上#号，以便于我们识别。\n",
    "\n",
    "        例子1：\n",
    "        历史记录：\n",
    "        r如何将数组变成字符串\n",
    "        enumerate放回参数\n",
    "        find如何能把div下面包的所有内容都找到\n",
    "        while至多3次怎么写\n",
    "        我有一个网页请求经常会失败，导致程序停止，我如何让它失败时再来两遍\n",
    "        \n",
    "        提取出的特征：\n",
    "        #用户经常提出编程问题。\\n#用户经常提出关于Python的问题。\n",
    "\n",
    "        例子2：\n",
    "        历史记录：\n",
    "        去北京旅游有什么交通出行的选择吗\n",
    "        北京有什么好玩的地方吗\n",
    "        北京有什么好吃的吗\n",
    "        北京有什么好玩的吗\n",
    "        北京著名景点有哪些\n",
    "\n",
    "        提取出的特征：\n",
    "        #用户喜欢旅游\\n#用户计划去北京。\n",
    "\n",
    "        以上例子以及特征与你所服务的客户无关，仅供参考。\n",
    "\n",
    "        历史记录：\n",
    "        {user_history}\n",
    "\n",
    "        提取出的特征：\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "def feature_extraction_prompt_prompter(history):\n",
    "    messages = []\n",
    "    messages.append({\"role\":\"user\",\"content\":feature_extraction_prompt_zjh_1(history)})\n",
    "    response = model.chat(tokenizer, messages)\n",
    "    # print(response)\n",
    "    pattern = r\"#(.*)\"\n",
    "    matches = re.findall(pattern, response)\n",
    "    # print(matches)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = '''\n",
    "Line 1053: Char 9: runtime error: addition of unsigned offset to 0x7ffd970ec650 overflowed to 0x7ffd970ec64f (basic_string.h)\n",
    "SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior /usr/bin/../lib/gcc/x86_64-linux-gnu/11/../../../../include/c++/11/bits/basic_string.h:1062:9这个怎么回事\n",
    "html文件如何用python改成{\"titile\":\"xxx\",\"content\":\"xxx\"}\n",
    "llm中strong reasoner什么意思\n",
    "instruction tuning改变参数吗\n",
    "'''\n",
    "match=feature_extraction_prompt_prompter(history)\n",
    "feature.append(match[0])\n",
    "# 也可以使用extend来将所有特征加上去，或者加一个也可以（使用append）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['用户对编程和计算机相关知识感兴趣。', '用户可能正在准备高考或大学入学考试。']\n"
     ]
    }
   ],
   "source": [
    "history = '''\n",
    "报考高校需要注意什么\n",
    "志愿填报分几个阶段\n",
    "土木工程什么学校比较好\n",
    "'''\n",
    "\n",
    "match=feature_extraction_prompt_prompter(history)\n",
    "feature.append(match[0])\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multistep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请逐个回答上述问题，一步步思考。\n",
      "\n",
      "1. AI助手你好，请你告诉我，一封标准的信件通常包括哪些部分？\n",
      "2. AI助手你好，请你告诉我，在信件的开头，我们应该使用什么样的称呼来表示对收信人的尊重和礼貌？\n",
      "3. AI助手你好，请你告诉我，在信件的结尾，我们应该使用什么样的结束语来表示对收信人的尊重和礼貌？\n",
      "4. AI助手你好，请你告诉我，在信件的正文部分，我们可以安排哪些内容来表达我们的观点或请求？\n"
     ]
    }
   ],
   "source": [
    "question=\"如何写一份信，格式要求是怎么样的\"\n",
    "multistep_prompt_prompter(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请逐个回答上述问题，一步步思考。\n",
      "\n",
      "1. 爱因斯坦作为一位理论物理学家，他的哪项成就使得他获得了诺贝尔物理学奖？\n"
     ]
    }
   ],
   "source": [
    "question=\"爱因斯坦为什么得诺贝尔奖\"\n",
    "multistep_prompt_prompter(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. AI助手你好，请你告诉我，中国哪些地区盛产辣椒？\n",
      "2. AI助手你好，请你告诉我，辣椒在中国的饮食文化中扮演着怎样的角色？\n",
      "3. AI助手你好，请你告诉我，为什么有些人会觉得辣椒好吃，而有些人则不喜欢？\n",
      "4. AI助手你好，请你告诉我，是否存在一些特殊的饮食习惯或地理环境因素导致了人们对辣椒的喜好？\n",
      "5. AI助手你好，请你告诉我，随着时间的推移，人们的口味是否会出现变化，例如更偏向于辛辣食物？\n"
     ]
    }
   ],
   "source": [
    "question=\"中国哪里人最能吃辣，这个和气候有关系吗，为什么他们会习惯甚至是喜欢吃辣，会不会随着时代发展吃辣的人变多呢\"\n",
    "multistep_prompt_prompter(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，chatgpt，我想向你咨询一下问题：在复旦大学中，张维维教授的研究方向和主要成就有哪些？\n"
     ]
    }
   ],
   "source": [
    "question1=\"复旦 张维维\"\n",
    "prompt_prompter(question1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$你好，chatҐPT，我想向你咨询一下问题：中国现在的经济地位如何？请详细解释并举例说明。\n"
     ]
    }
   ],
   "source": [
    "question2=\"中国现在低位\"\n",
    "prompt_prompter(question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，chatgpt，我想向你咨询一下问题：你能详细解释一下维达定理吗？谢谢！\n"
     ]
    }
   ],
   "source": [
    "question3=\"请为我介绍维达定理\"\n",
    "prompt_prompter(question3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，chatgpt，我想向你咨询一下问题：如果我要选择一所中国顶尖的大学进行学习，是应该选择复旦大学还是上海交通大学呢？\n"
     ]
    }
   ],
   "source": [
    "question4=\"复旦和交大选哪个\"\n",
    "prompt_prompter(question4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$你好，chatgpt，我想向你咨询一下问题：能否简单解释一下什么叫做数学归纳法？谢谢！\n"
     ]
    }
   ],
   "source": [
    "question5=\"什么是数学归纳法，我不懂\"\n",
    "prompt_prompter(question5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，chatgpt，我想向你咨询一下问题：如何规划一次北京之行以便我和我的女朋友共同度过一段愉快的时光？\n"
     ]
    }
   ],
   "source": [
    "question6=\"我想和女朋友去北京玩，有攻略吗\"\n",
    "prompt_prompter(question6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，chatgpt，我想向你咨询一下问题：如果你是一名大学生，早晨总是难以按时起床，有哪些策略或者方法可以帮助你改善这个情况呢？\n"
     ]
    }
   ],
   "source": [
    "question7=\"大学生早上起不来咋办\"\n",
    "prompt_prompter(question7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
