{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting bigdl-llm[all]\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fe/e8/5932d5380c1964bdecb851268045c7b707b55ad97f0a46dae6e2e927f82c/bigdl_llm-2.4.0b20231003-py3-none-win_amd64.whl (3.7 MB)\n",
      "     ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.7 MB 960.0 kB/s eta 0:00:04\n",
      "     -- ------------------------------------- 0.2/3.7 MB 2.3 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 0.4/3.7 MB 3.4 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 0.6/3.7 MB 4.2 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 0.9/3.7 MB 4.7 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 1.2/3.7 MB 4.9 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 1.4/3.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 1.8/3.7 MB 5.6 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 2.0/3.7 MB 5.7 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 2.2/3.7 MB 5.5 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 2.3/3.7 MB 5.4 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 2.4/3.7 MB 5.4 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 2.6/3.7 MB 5.3 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 2.8/3.7 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 3.0/3.7 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 3.2/3.7 MB 5.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 3.4/3.7 MB 5.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 3.6/3.7 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.7/3.7 MB 5.0 MB/s eta 0:00:00\n",
      "Collecting py-cpuinfo (from bigdl-llm[all])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e0/a9/023730ba63db1e494a271cb018dcd361bd2c917ba7004c3e49d5daf795a2/py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting protobuf (from bigdl-llm[all])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c2/59/f89c04923d68595d359f4cd7adbbdf5e5d791257945f8873d88b2fd1f979/protobuf-4.24.4-cp310-abi3-win_amd64.whl (430 kB)\n",
      "     ---------------------------------------- 0.0/430.5 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 194.6/430.5 kB 5.9 MB/s eta 0:00:01\n",
      "     ---------------------------- --------- 317.4/430.5 kB 4.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 430.5/430.5 kB 4.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from bigdl-llm[all]) (1.25.1)\n",
      "Requirement already satisfied: torch in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from bigdl-llm[all]) (2.0.1)\n",
      "Requirement already satisfied: transformers==4.31.0 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from bigdl-llm[all]) (4.31.0)\n",
      "Collecting sentencepiece (from bigdl-llm[all])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/cc/07/d6951e3b4079df819d76353302fc3e76835252e7e0b6366f96a03d87ea5f/sentencepiece-0.1.99-cp311-cp311-win_amd64.whl (977 kB)\n",
      "     ---------------------------------------- 0.0/977.5 kB ? eta -:--:--\n",
      "     ------ ------------------------------- 174.1/977.5 kB 5.3 MB/s eta 0:00:01\n",
      "     --------------- ---------------------- 389.1/977.5 kB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------- --------------- 583.7/977.5 kB 4.6 MB/s eta 0:00:01\n",
      "     ----------------------------- -------- 747.5/977.5 kB 4.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- --- 890.9/977.5 kB 4.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 977.5/977.5 kB 4.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tokenizers==0.13.3 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from bigdl-llm[all]) (0.13.3)\n",
      "Collecting accelerate==0.21.0 (from bigdl-llm[all])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/70/f9/c381bcdd0c3829d723aa14eec8e75c6c377b4ca61ec68b8093d9f35fc7a7/accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
      "Collecting tabulate (from bigdl-llm[all])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/40/44/4a5f08c96eb108af5cb50b41f76142f0afa346dfa99d5296fe7202a11854/tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from accelerate==0.21.0->bigdl-llm[all]) (23.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from accelerate==0.21.0->bigdl-llm[all]) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from accelerate==0.21.0->bigdl-llm[all]) (6.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (0.16.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (2023.6.3)\n",
      "Requirement already satisfied: requests in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from torch->bigdl-llm[all]) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from torch->bigdl-llm[all]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from torch->bigdl-llm[all]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from torch->bigdl-llm[all]) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0->bigdl-llm[all]) (2023.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from tqdm>=4.27->transformers==4.31.0->bigdl-llm[all]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from jinja2->torch->bigdl-llm[all]) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from requests->transformers==4.31.0->bigdl-llm[all]) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from requests->transformers==4.31.0->bigdl-llm[all]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from requests->transformers==4.31.0->bigdl-llm[all]) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from requests->transformers==4.31.0->bigdl-llm[all]) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from sympy->torch->bigdl-llm[all]) (1.3.0)\n",
      "Installing collected packages: sentencepiece, py-cpuinfo, bigdl-llm, tabulate, protobuf, accelerate\n",
      "Successfully installed accelerate-0.21.0 bigdl-llm-2.4.0b20231003 protobuf-4.24.4 py-cpuinfo-9.0.0 sentencepiece-0.1.99 tabulate-0.9.0\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting transformers_stream_generator\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/36/26/3492ab0e45d814533b34ca605f8a20fdc032736f937679c6f212d81a76a5/transformers-stream-generator-0.0.4.tar.gz (12 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: transformers>=4.26.1 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers_stream_generator) (4.31.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (1.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (2023.6.3)\n",
      "Requirement already satisfied: requests in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (4.65.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.26.1->transformers_stream_generator) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.26.1->transformers_stream_generator) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from tqdm>=4.27->transformers>=4.26.1->transformers_stream_generator) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\86177\\anaconda3\\envs\\vllm\\lib\\site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2023.7.22)\n",
      "Building wheels for collected packages: transformers_stream_generator\n",
      "  Building wheel for transformers_stream_generator (setup.py): started\n",
      "  Building wheel for transformers_stream_generator (setup.py): finished with status 'done'\n",
      "  Created wheel for transformers_stream_generator: filename=transformers_stream_generator-0.0.4-py3-none-any.whl size=12346 sha256=ee32f81665172280641c7edfde4c50519355c1d3fadf28f0648c409ef7d9788a\n",
      "  Stored in directory: c:\\users\\86177\\appdata\\local\\pip\\cache\\wheels\\67\\b9\\80\\b1c50466969dad23d740daaa6a9aeaa6daf59b7670f08d414f\n",
      "Successfully built transformers_stream_generator\n",
      "Installing collected packages: transformers_stream_generator\n",
      "Successfully installed transformers_stream_generator-0.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install bigdl-llm[all]\n",
    "\n",
    "# Additional package required for Baichuan-13B-Chat to conduct generation\n",
    "!pip install -U transformers_stream_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\86177\\anaconda3\\envs\\vllm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bigdl.llm.transformers import AutoModelForCausalLM\n",
    "\n",
    "model_path = \"C:\\LLM\\llm-model\\saved-int4-models\\Baichuan-13B-Chat\"\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_path,\n",
    "#                                             load_in_4bit=True,\n",
    "#                                             trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.load_low_bit(model_path,trust_remote_code=True)\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path,\n",
    "                                          trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.generation.utils import GenerationConfig\n",
    "model.generation_config = GenerationConfig.from_pretrained(\"C:\\LLM\\llm-model\\saved-int4-models\\Baichuan-13B-Chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multistep_prompt_zjh_1(user_input):\n",
    "    return f\"\"\"您是一个大型语言模型提示词撰写专家。\n",
    "        用户的输入可能涉及一个复杂的问题，如果直接让语言模型回答这个问题效果并不好。你的目的是将用户的问题拆分为几个小问题，让语言模型一步步思考，逐渐靠近答案。优化过的问题将以“请逐个回答上述问题，一步步思考。”结尾。\n",
    "\n",
    "        例子：\n",
    "        输入：\n",
    "        我希望按欧式风格装修房子，要花费多少钱？\n",
    "\n",
    "        修改后的输入：\n",
    "        1.AI助手你好，欧式风格的房子主要有哪些家具？\\n2.AI助手你好，欧式风格的家具一般需要多少钱？\\n3.AI助手你好，完成欧式风格的装修总共需要多少钱？\\n请逐个回答上述问题，一步步思考。\n",
    "\n",
    "        原来的输入如下：\n",
    "        {user_input}\n",
    "\n",
    "        修改的输入如下：\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def multistep_prompt_prompter(question):\n",
    "    messages = []\n",
    "    messages.append({\"role\":\"user\",\"content\":multistep_prompt_zjh_1(question)})\n",
    "    response = model.chat(tokenizer, messages)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_prompt_zjh_1(user_history):\n",
    "    return f\"\"\"您是独属于该用户的提示词管家。\n",
    "        您会定期看到用户向大型语言模型提问的历史记录，你需要根据这些历史提问，提取出几个用户的特征，包括但不限于使用语言、倾向于提出的问题类型、提问的立场、用户可能的身份、经常犯的逻辑谬误等等。\n",
    "        我们会将这些特征加入到大型语言模型的prompt中，以便于模型更好地理解用户的提问。\n",
    "        你需要在每个特征前面加上#号，以便于我们识别。\n",
    "\n",
    "        例子1：\n",
    "        历史记录：\n",
    "        r如何将数组变成字符串\n",
    "        enumerate放回参数\n",
    "        find如何能把div下面包的所有内容都找到\n",
    "        while至多3次怎么写\n",
    "        我有一个网页请求经常会失败，导致程序停止，我如何让它失败时再来两遍\n",
    "        \n",
    "        提取出的特征：\n",
    "        #用户经常提出编程问题。\\n#用户经常提出关于Python的问题。\n",
    "\n",
    "        例子2：\n",
    "        历史记录：\n",
    "        去北京旅游有什么交通出行的选择吗\n",
    "        北京有什么好玩的地方吗\n",
    "        北京有什么好吃的吗\n",
    "        北京有什么好玩的吗\n",
    "        北京著名景点有哪些\n",
    "\n",
    "        提取出的特征：\n",
    "        #用户喜欢旅游\\n#用户计划去北京。\n",
    "\n",
    "        以上例子以及特征与你所服务的客户无关，仅供参考。\n",
    "\n",
    "        历史记录：\n",
    "        {user_history}\n",
    "\n",
    "        提取出的特征：\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "def feature_extraction_prompt_prompter(history):\n",
    "    messages = []\n",
    "    messages.append({\"role\":\"user\",\"content\":feature_extraction_prompt_zjh_1(history)})\n",
    "    response = model.chat(tokenizer, messages)\n",
    "    # print(response)\n",
    "    pattern = r\"#(.*)\"\n",
    "    matches = re.findall(pattern, response)\n",
    "    # print(matches)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = '''\n",
    "Line 1053: Char 9: runtime error: addition of unsigned offset to 0x7ffd970ec650 overflowed to 0x7ffd970ec64f (basic_string.h)\n",
    "SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior /usr/bin/../lib/gcc/x86_64-linux-gnu/11/../../../../include/c++/11/bits/basic_string.h:1062:9这个怎么回事\n",
    "html文件如何用python改成{\"titile\":\"xxx\",\"content\":\"xxx\"}\n",
    "llm中strong reasoner什么意思\n",
    "instruction tuning改变参数吗\n",
    "'''\n",
    "match=feature_extraction_prompt_prompter(history)\n",
    "feature.append(match[0])\n",
    "# 也可以使用extend来将所有特征加上去，或者加一个也可以（使用append）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['用户对编程和计算机相关知识感兴趣。', '用户可能正在准备高考或大学入学考试。']\n"
     ]
    }
   ],
   "source": [
    "history = '''\n",
    "报考高校需要注意什么\n",
    "志愿填报分几个阶段\n",
    "土木工程什么学校比较好\n",
    "'''\n",
    "\n",
    "match=feature_extraction_prompt_prompter(history)\n",
    "feature.append(match[0])\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multistep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请分以下步骤回答上述问题：\n",
      "\n",
      "1.首先确定你想要提供的 afp 的种类和数量。例如，你可以提供三道不同的菜肴，每道价格为 $5，那么总费用就是 $5 x 3 = $15。\n"
     ]
    }
   ],
   "source": [
    "question=\"我想准备一顿烛光晚餐，需要花费多少钱？\"\n",
    "multistep_prompt_prompter(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，chatgpt，我想向你咨询一下问题：在复旦大学中，张维维教授的研究方向和主要成就有哪些？\n"
     ]
    }
   ],
   "source": [
    "question1=\"复旦 张维维\"\n",
    "prompt_prompter(question1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$你好，chatҐPT，我想向你咨询一下问题：中国现在的经济地位如何？请详细解释并举例说明。\n"
     ]
    }
   ],
   "source": [
    "question2=\"中国现在低位\"\n",
    "prompt_prompter(question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，chatgpt，我想向你咨询一下问题：你能详细解释一下维达定理吗？谢谢！\n"
     ]
    }
   ],
   "source": [
    "question3=\"请为我介绍维达定理\"\n",
    "prompt_prompter(question3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，chatgpt，我想向你咨询一下问题：如果我要选择一所中国顶尖的大学进行学习，是应该选择复旦大学还是上海交通大学呢？\n"
     ]
    }
   ],
   "source": [
    "question4=\"复旦和交大选哪个\"\n",
    "prompt_prompter(question4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$你好，chatgpt，我想向你咨询一下问题：能否简单解释一下什么叫做数学归纳法？谢谢！\n"
     ]
    }
   ],
   "source": [
    "question5=\"什么是数学归纳法，我不懂\"\n",
    "prompt_prompter(question5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，chatgpt，我想向你咨询一下问题：如何规划一次北京之行以便我和我的女朋友共同度过一段愉快的时光？\n"
     ]
    }
   ],
   "source": [
    "question6=\"我想和女朋友去北京玩，有攻略吗\"\n",
    "prompt_prompter(question6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，chatgpt，我想向你咨询一下问题：如果你是一名大学生，早晨总是难以按时起床，有哪些策略或者方法可以帮助你改善这个情况呢？\n"
     ]
    }
   ],
   "source": [
    "question7=\"大学生早上起不来咋办\"\n",
    "prompt_prompter(question7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
