{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: bigdl-llm[all] in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (2.4.0b20230912)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from bigdl-llm[all]) (9.0.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from bigdl-llm[all]) (4.24.3)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from bigdl-llm[all]) (1.24.4)\n",
      "Requirement already satisfied: torch in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from bigdl-llm[all]) (2.0.1)\n",
      "Requirement already satisfied: transformers==4.31.0 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from bigdl-llm[all]) (4.31.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from bigdl-llm[all]) (0.1.99)\n",
      "Requirement already satisfied: accelerate==0.21.0 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from bigdl-llm[all]) (0.21.0)\n",
      "Requirement already satisfied: tabulate in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from bigdl-llm[all]) (0.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from accelerate==0.21.0->bigdl-llm[all]) (23.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from accelerate==0.21.0->bigdl-llm[all]) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from accelerate==0.21.0->bigdl-llm[all]) (6.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (3.12.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (0.17.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (2023.8.8)\n",
      "Requirement already satisfied: requests in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from transformers==4.31.0->bigdl-llm[all]) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from torch->bigdl-llm[all]) (4.8.0rc1)\n",
      "Requirement already satisfied: sympy in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from torch->bigdl-llm[all]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from torch->bigdl-llm[all]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from torch->bigdl-llm[all]) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0->bigdl-llm[all]) (2023.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from tqdm>=4.27->transformers==4.31.0->bigdl-llm[all]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from jinja2->torch->bigdl-llm[all]) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from requests->transformers==4.31.0->bigdl-llm[all]) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from requests->transformers==4.31.0->bigdl-llm[all]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from requests->transformers==4.31.0->bigdl-llm[all]) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from requests->transformers==4.31.0->bigdl-llm[all]) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from sympy->torch->bigdl-llm[all]) (1.3.0)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: transformers_stream_generator in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (0.0.4)\n",
      "Requirement already satisfied: transformers>=4.26.1 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from transformers_stream_generator) (4.31.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (3.12.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (0.17.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (2023.8.8)\n",
      "Requirement already satisfied: requests in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (4.66.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.26.1->transformers_stream_generator) (2023.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.26.1->transformers_stream_generator) (4.8.0rc1)\n",
      "Requirement already satisfied: colorama in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from tqdm>=4.27->transformers>=4.26.1->transformers_stream_generator) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\86177\\anaconda3\\envs\\llm-tutorial\\lib\\site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install bigdl-llm[all]\n",
    "\n",
    "# Additional package required for Baichuan-13B-Chat to conduct generation\n",
    "!pip install -U transformers_stream_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigdl.llm.transformers import AutoModelForCausalLM\n",
    "\n",
    "model_path = \"C:\\LLM\\llm-model\\saved-int4-models\\Baichuan-13B-Chat\"\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_path,\n",
    "#                                             load_in_4bit=True,\n",
    "#                                             trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.load_low_bit(model_path,trust_remote_code=True)\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path,\n",
    "                                          trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.generation.utils import GenerationConfig\n",
    "model.generation_config = GenerationConfig.from_pretrained(\"C:\\LLM\\llm-model\\saved-int4-models\\Baichuan-13B-Chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prompt_prompter(question):\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"system\", \"content\": \"用户会向你提供一个问题，你需要将问题修改为更好的问题输出，请注意输出问题不针对用户，不是对于用户需求的再度确认，而站在用户视角可以用于向更强大的语言模型提问。换句话说，你要替用户问出更好的问题，在此过程中，你需要让问题更加明确、最好能提供例子说明、改正问题中的语法错误以及事实性错误。你的回答将以$你好，chatgpt，我想向你咨询一下问题：$开头。\\n比方说：\\n问题输入$复旦 哲学系$\\n问题输出$你好，chatgpt，我想向你咨询一下问题：复旦哲学系专业实力怎么样？请为我介绍其概括。$\\n问题输入$长城再哪里$\\n问题输出$你好，chatgpt，我想向你咨询一下问题：长城在哪里$\\n问题输入$container复数$\\n问题输出$你好，chatgpt，我想向你咨询一下问题：英语单词container的复数形式是什么$\"})\n",
    "    messages.append({\"role\":\"user\",\"content\":question})\n",
    "    response = model.chat(tokenizer, messages)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，chatgpt，我想向你咨询一下问题：在复旦大学中，张维维教授的研究方向和主要成就有哪些？\n"
     ]
    }
   ],
   "source": [
    "question1=\"复旦 张维维\"\n",
    "prompt_prompter(question1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$你好，chatҐPT，我想向你咨询一下问题：中国现在的经济地位如何？请详细解释并举例说明。\n"
     ]
    }
   ],
   "source": [
    "question2=\"中国现在低位\"\n",
    "prompt_prompter(question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，chatgpt，我想向你咨询一下问题：你能详细解释一下维达定理吗？谢谢！\n"
     ]
    }
   ],
   "source": [
    "question3=\"请为我介绍维达定理\"\n",
    "prompt_prompter(question3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，chatgpt，我想向你咨询一下问题：如果我要选择一所中国顶尖的大学进行学习，是应该选择复旦大学还是上海交通大学呢？\n"
     ]
    }
   ],
   "source": [
    "question4=\"复旦和交大选哪个\"\n",
    "prompt_prompter(question4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$你好，chatgpt，我想向你咨询一下问题：能否简单解释一下什么叫做数学归纳法？谢谢！\n"
     ]
    }
   ],
   "source": [
    "question5=\"什么是数学归纳法，我不懂\"\n",
    "prompt_prompter(question5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，chatgpt，我想向你咨询一下问题：如何规划一次北京之行以便我和我的女朋友共同度过一段愉快的时光？\n"
     ]
    }
   ],
   "source": [
    "question6=\"我想和女朋友去北京玩，有攻略吗\"\n",
    "prompt_prompter(question6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，chatgpt，我想向你咨询一下问题：如果你是一名大学生，早晨总是难以按时起床，有哪些策略或者方法可以帮助你改善这个情况呢？\n"
     ]
    }
   ],
   "source": [
    "question7=\"大学生早上起不来咋办\"\n",
    "prompt_prompter(question7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
